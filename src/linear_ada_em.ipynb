{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report\n",
    "from scipy.stats import ks_2samp\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from datetime import datetime\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn2pmml.decoration import CategoricalDomain, ContinuousDomain\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "# from project_demo.tools.optimize import *\n",
    "from project_demo.tools.evaluate import *\n",
    "%matplotlib inline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线形组合和adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_ks(model, dataframemapper, trainset, testset, varlist,train_only=False):\n",
    "    if train_only == False:\n",
    "        df_test=dataframemapper.transform(testset)\n",
    "        predprob = pd.DataFrame(model.predict_proba(df_test[varlist])[:,1], columns = ['predprob'])\n",
    "        predprob['ytrue'] = testset['perf'].values\n",
    "        auc = roc_auc_score(y_score=predprob['predprob'], y_true=predprob['ytrue'])\n",
    "        print('AUC On Test is: {}'.format(auc))\n",
    "        print('KS On Test is: {}'.format(cal_ks_scipy(predprob['predprob'], predprob['ytrue'])))\n",
    "        predprob_test = predprob\n",
    "    \n",
    "    df_train=dataframemapper.transform(trainset)\n",
    "    predprob = pd.DataFrame(model.predict_proba(df_train[varlist])[:,1], columns = ['predprob'])\n",
    "    predprob['ytrue'] = trainset['perf'].values\n",
    "    auc = roc_auc_score(y_score=predprob['predprob'], y_true=predprob['ytrue'])\n",
    "    print('AUC On Train is: {}'.format(auc))\n",
    "    print('KS On Train is: {}'.format(cal_ks_scipy(predprob['predprob'], predprob['ytrue'])))\n",
    "    return predprob['predprob'], predprob['ytrue'],predprob_test['predprob'],predprob_test['ytrue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ks(df_score, df_good,fig_dir):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df_score = pd.DataFrame(df_score)\n",
    "    df_good = pd.DataFrame(df_good) \n",
    "    df_score.columns = ['score']\n",
    "    df_good.columns = ['good']\n",
    "    df = pd.concat([df_score,df_good],axis=1)\n",
    "    \n",
    "    df['bad'] = 1 - df.good\n",
    "    bin = np.arange(0, 1.001, 0.05)\n",
    "    df['bucket'] = pd.cut(df.score, bin)  # 根据bin来划分区间\n",
    "   \n",
    "    grouped = df.groupby('bucket', as_index=False) # 统计在每个区间的样本量\n",
    "    agg1 = pd.DataFrame()\n",
    "    agg1['min_scr'] = grouped.min().score # 取得每个区间的最小值\n",
    "    agg1['max_scr'] = grouped.max().score\n",
    "    agg1['bads'] = grouped.sum().bad # 计算每个区间bad的总数量\n",
    "    agg1['goods'] = grouped.sum().good\n",
    "    \n",
    "    agg2 = (agg1.sort_values(['min_scr'])).reset_index(drop=True) # 根据区间最小值排序\n",
    "    agg2['bad_cum_rate'] = np.round((agg2.bads / df.bad.sum()).cumsum(), 4) # 计算bad样本累计概率\n",
    "    agg2['good_cum_rate'] = np.round((agg2.goods / df.good.sum()).cumsum(), 4) \n",
    "    agg2['ks'] = abs(np.round(((agg2.bads / df.bad.sum()).cumsum() - (agg2.goods / df.good.sum()).cumsum()), 4)) # 计算bad和good累计概率之差的绝对值\n",
    "    ks = agg2.ks.max()  # 求出ks\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))  # 创建绘图对象\n",
    "    plt.plot(agg2.min_scr, agg2.bad_cum_rate, \"g-\", linewidth=1)  # 在当前绘图对象绘图（X轴，Y轴，蓝色虚线，线宽度）\n",
    "    plt.plot(agg2.min_scr, agg2.good_cum_rate, \"b-\", linewidth=1)\n",
    "    \n",
    "    x_abline = agg2['min_scr'][agg2['ks'] == agg2['ks'].max()] # ks最大的min_scr\n",
    "    y_abline1 = agg2['bad_cum_rate'][agg2['ks'] == agg2['ks'].max()] # ks最大时bad_cum_rate\n",
    "    y_abline2 = agg2['good_cum_rate'][agg2['ks'] == agg2['ks'].max()]\n",
    "    plt.fill_between(x_abline, y_abline1, y_abline2, color = \"red\",linewidth=2)    \n",
    "    \n",
    "    sub = \"%s%s\"%('ks = ',ks)\n",
    "    plt.legend(title=sub,loc='lower right')\n",
    "    plt.xlabel(\"Minimum score\")  # X轴标签\n",
    "    plt.ylabel(\"Cumulative percentage(%)\")  # Y轴标签\n",
    "    plt.title('KS chart')  # 图标题\n",
    "    plt.savefig(fig_dir)\n",
    "    plt.show()  # 显示图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_ks_v(model, dataframemapper, trainset, testset, varlist,train_only=False):\n",
    "    if train_only == False:\n",
    "        df_test=dataframemapper.transform(testset)\n",
    "        predprob = pd.DataFrame(model.predict_proba(df_test[varlist])[:,1], columns = ['predprob'])\n",
    "        predprob['ytrue'] = testset['perf'].values\n",
    "        auc = roc_auc_score(y_score=predprob['predprob'], y_true=predprob['ytrue'])\n",
    "        print('AUC On valid is: {}'.format(auc))\n",
    "        print('KS On valid is: {}'.format(cal_ks_scipy(predprob['predprob'], predprob['ytrue'])))\n",
    "    \n",
    "    df_train=dataframemapper.transform(trainset)\n",
    "    predprob = pd.DataFrame(model.predict_proba(df_train[varlist])[:,1], columns = ['predprob'])\n",
    "    predprob['ytrue'] = trainset['perf'].values\n",
    "    auc = roc_auc_score(y_score=predprob['predprob'], y_true=predprob['ytrue'])\n",
    "    print('AUC On Train is: {}'.format(auc))\n",
    "    print('KS On Train is: {}'.format(cal_ks_scipy(predprob['predprob'], predprob['ytrue'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continuous_categorical(dataset):\n",
    "    '''diff continuous and categorical\n",
    "        \n",
    "    '''\n",
    "    continuousDomain = [] # float int\n",
    "    categoricalDomain = [] # object bool category\n",
    "\n",
    "    for item in dataset.columns:\n",
    "        if (dataset[item].dtypes == object)| (dataset[item].dtypes == bool):\n",
    "            categoricalDomain.append(item)\n",
    "            dataset[item] = dataset[item].astype(str)\n",
    "        elif item!='target':\n",
    "            continuousDomain.append(item)\n",
    "            dataset[item] = dataset[item]\n",
    "    print (categoricalDomain)\n",
    "    return continuousDomain,categoricalDomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model_stability(proba_train, proba_validation, segment_cnt = 10,out_path=False):\n",
    "    \"\"\"\n",
    "    :param proba_train: 训练集预测概率\n",
    "    :param proba_validation: 验证集预测概率\n",
    "    :param segment_cnt:\n",
    "    :param out_path:\n",
    "    :return: 模型稳定性\n",
    "    \"\"\"\n",
    "    step = 1.0/segment_cnt\n",
    "    flag = 0.0\n",
    "    model_stability = []\n",
    "    len_train = len(proba_train)\n",
    "    len_validation = len(proba_validation)\n",
    "\n",
    "    columns = ['score_range','segment_train_percentage','segment_validation_percentage','difference',\n",
    "               'variance','ln_variance','stability_index']\n",
    "\n",
    "    while flag < 1.0:\n",
    "        temp = {}\n",
    "\n",
    "        score_range = '['+str(flag)+','+str(flag + step)+')'\n",
    "        segment_train_cnt = proba_train[(proba_train >= flag) & (proba_train < flag + step)].count()\n",
    "        segment_train_percentage = segment_train_cnt*1.0/len_train\n",
    "        segment_validation_cnt = proba_validation[(proba_validation >= flag) & (proba_validation < flag + step)].count()\n",
    "        segment_validation_percentage = segment_validation_cnt * 1.0 / len_validation\n",
    "        difference = segment_validation_percentage - segment_train_percentage\n",
    "        variance = float(segment_validation_percentage)/segment_train_percentage\n",
    "        ln_variance = variance\n",
    "        stability_index = difference * ln_variance\n",
    "\n",
    "        temp['score_range'] = score_range\n",
    "        temp['segment_train_percentage'] = segment_train_percentage[0]\n",
    "        temp['segment_validation_percentage'] = segment_validation_percentage[0]\n",
    "        temp['difference'] = difference[0]\n",
    "        temp['variance'] = variance[0]\n",
    "        temp['ln_variance'] = ln_variance[0]\n",
    "        temp['stability_index'] = stability_index[0]\n",
    "\n",
    "        model_stability.append(temp)\n",
    "        flag += step\n",
    "\n",
    "    model_stability = pd.DataFrame(model_stability,columns=columns)\n",
    "    if out_path:\n",
    "        file_name = out_path if isinstance(out_path, str) else None\n",
    "        model_stability.to_csv(file_name, index=False)\n",
    "\n",
    "    return model_stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tb_file/data/linear_ada_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_fasttext = pd.read_csv('tb_flie/data/linear_ada_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_fasttext =pre_fasttext.rename(columns={'target_y':'perf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ugid</th>\n",
       "      <th>token_id_x</th>\n",
       "      <th>TB1</th>\n",
       "      <th>TB5</th>\n",
       "      <th>TB9</th>\n",
       "      <th>TB3</th>\n",
       "      <th>TB7</th>\n",
       "      <th>TB11</th>\n",
       "      <th>TB2</th>\n",
       "      <th>TB6</th>\n",
       "      <th>...</th>\n",
       "      <th>TO218</th>\n",
       "      <th>TO208</th>\n",
       "      <th>TO221</th>\n",
       "      <th>TO198</th>\n",
       "      <th>TO211</th>\n",
       "      <th>token_id</th>\n",
       "      <th>crawler_time</th>\n",
       "      <th>last_decision_tm_y</th>\n",
       "      <th>perf</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ugid, token_id_x, TB1, TB5, TB9, TB3, TB7, TB11, TB2, TB6, TB10, TB4, TB8, TB12, TB321, TB322, TB323, TB324, TB325, TB326, TB327, TB328, TB329, TB330, TB331, TB332, TB333, TB334, TB335, TB336, TB337, TB338, TB339, TB340, TB341, TB342, TB343, TB344, TB345, TB346, TB347, TB348, TB349, TB434, TB435, TB436, TB437, TB366, TB367, TB368, TB369, TB370, TB371, TB372, TB373, TB374, TB375, TB376, TB377, TB378, TB379, TB380, TB381, TB382, TB383, TB384, TB385, TB386, TB387, TB388, TB389, TB390, TB391, TB392, TB393, TB394, TB395, TB396, TB397, TB13, TB16, TB19, TB14, TB17, TB20, TB15, TB18, TB21, TB22, TB26, TB30, TB24, TB28, TB32, TB23, TB27, TB31, TB25, TB29, TB33, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 901 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_fasttext.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ugid</th>\n",
       "      <th>token_id_x</th>\n",
       "      <th>TO9</th>\n",
       "      <th>TO10</th>\n",
       "      <th>TO52</th>\n",
       "      <th>TO51</th>\n",
       "      <th>TO17</th>\n",
       "      <th>TO54</th>\n",
       "      <th>TO27</th>\n",
       "      <th>TO28</th>\n",
       "      <th>...</th>\n",
       "      <th>TB296</th>\n",
       "      <th>crawler_time</th>\n",
       "      <th>TO414_y</th>\n",
       "      <th>TO415_y</th>\n",
       "      <th>TO416_y</th>\n",
       "      <th>TO417_y</th>\n",
       "      <th>TO418_y</th>\n",
       "      <th>first_trans_time</th>\n",
       "      <th>perf</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00024CEF-E433-4679-B85E-2237CF46A2B2</td>\n",
       "      <td>7d4e87d01f44479296e43124b4a979461488774175767_21</td>\n",
       "      <td>3672</td>\n",
       "      <td>2149</td>\n",
       "      <td>131490</td>\n",
       "      <td>234504</td>\n",
       "      <td>1523</td>\n",
       "      <td>103014</td>\n",
       "      <td>899</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>06MAR17:12:39:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-22 19:18:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002BE1A-3E99-48F4-9C9C-B075B9D85BA7</td>\n",
       "      <td>4e31ee0c90e34879b798d4fd69714eca1486560721411_21</td>\n",
       "      <td>2960</td>\n",
       "      <td>1381</td>\n",
       "      <td>105290</td>\n",
       "      <td>212868</td>\n",
       "      <td>1579</td>\n",
       "      <td>107578</td>\n",
       "      <td>603</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>09MAR17:23:27:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-21 17:09:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00044410-EB5A-4F23-B629-64570EE71897</td>\n",
       "      <td>5cd370d2a346471593434f67ac9a00011493171833156_21</td>\n",
       "      <td>3558</td>\n",
       "      <td>1410</td>\n",
       "      <td>142013</td>\n",
       "      <td>435017</td>\n",
       "      <td>2148</td>\n",
       "      <td>293004</td>\n",
       "      <td>739</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>26APR17:10:10:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-26 10:26:08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00046111-B639-4791-8FA9-F0D1906C326A</td>\n",
       "      <td>0e8d2d819cdd4f6a82e5af468c956a361495350053263_21</td>\n",
       "      <td>603</td>\n",
       "      <td>241</td>\n",
       "      <td>11384</td>\n",
       "      <td>30644</td>\n",
       "      <td>362</td>\n",
       "      <td>19260</td>\n",
       "      <td>194</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>21MAY17:15:38:19</td>\n",
       "      <td>68.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-21 15:41:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000485EE-1971-4FCB-82A4-6A9A4BCF3A29</td>\n",
       "      <td>8641267920004cc79cc715c6563baee51495098191611_21</td>\n",
       "      <td>184</td>\n",
       "      <td>98</td>\n",
       "      <td>7026</td>\n",
       "      <td>16674</td>\n",
       "      <td>86</td>\n",
       "      <td>9648</td>\n",
       "      <td>177</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>18MAY17:23:59:57</td>\n",
       "      <td>709.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-05-19 00:01:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 895 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ugid  \\\n",
       "0  00024CEF-E433-4679-B85E-2237CF46A2B2   \n",
       "1  0002BE1A-3E99-48F4-9C9C-B075B9D85BA7   \n",
       "2  00044410-EB5A-4F23-B629-64570EE71897   \n",
       "3  00046111-B639-4791-8FA9-F0D1906C326A   \n",
       "4  000485EE-1971-4FCB-82A4-6A9A4BCF3A29   \n",
       "\n",
       "                                         token_id_x   TO9  TO10    TO52  \\\n",
       "0  7d4e87d01f44479296e43124b4a979461488774175767_21  3672  2149  131490   \n",
       "1  4e31ee0c90e34879b798d4fd69714eca1486560721411_21  2960  1381  105290   \n",
       "2  5cd370d2a346471593434f67ac9a00011493171833156_21  3558  1410  142013   \n",
       "3  0e8d2d819cdd4f6a82e5af468c956a361495350053263_21   603   241   11384   \n",
       "4  8641267920004cc79cc715c6563baee51495098191611_21   184    98    7026   \n",
       "\n",
       "     TO51  TO17    TO54  TO27  TO28    ...     TB296      crawler_time  \\\n",
       "0  234504  1523  103014   899   161    ...        13  06MAR17:12:39:58   \n",
       "1  212868  1579  107578   603   171    ...         7  09MAR17:23:27:01   \n",
       "2  435017  2148  293004   739   196    ...         6  26APR17:10:10:02   \n",
       "3   30644   362   19260   194    94    ...        13  21MAY17:15:38:19   \n",
       "4   16674    86    9648   177    69    ...        33  18MAY17:23:59:57   \n",
       "\n",
       "   TO414_y  TO415_y  TO416_y  TO417_y  TO418_y     first_trans_time  perf  \\\n",
       "0      NaN      NaN      NaN      NaN      NaN  2017-04-22 19:18:22     0   \n",
       "1      NaN      NaN      NaN      NaN      NaN  2017-03-21 17:09:05     0   \n",
       "2      NaN      NaN      NaN      NaN      NaN  2017-04-26 10:26:08     1   \n",
       "3     68.0    119.0    137.0    137.0      3.0  2017-05-21 15:41:15     1   \n",
       "4    709.0    270.0    185.0    152.0      7.0  2017-05-19 00:01:31     1   \n",
       "\n",
       "       prob  \n",
       "0  0.296029  \n",
       "1  0.415101  \n",
       "2  0.598104  \n",
       "3  0.052565  \n",
       "4  0.461610  \n",
       "\n",
       "[5 rows x 895 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delete_list_2 = ['ugid','token_id_x','crawler_time','token_id_y','crawler_time_x', 'ugid_y', 'crawler_time_y', 'last_decision_tm_x', 'token_id', 'last_decision_tm_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delete_list_1 = ['ugid','token_id_x','crawler_time','token_id_y','first_trans_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = ['crawler_time','token_id_y']\n",
    "pre_fasttext =pre_fasttext.drop(delete_list_2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =data.drop(delete_list_1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data =data.drop(d,axis=1)\n",
    "pre_fasttext.replace(np.inf, np.nan, inplace=True)\n",
    "pre_fasttext.replace(-99998,np.nan, inplace=True)\n",
    "pre_fasttext.replace(-99999976,np.nan, inplace=True)\n",
    "pre_fasttext.replace(-9999979,np.nan, inplace=True)\n",
    "pre_fasttext.replace(-9999976,np.nan, inplace=True)\n",
    "pre_fasttext.replace(-999973,np.nan, inplace=True)\n",
    "pre_fasttext.replace(-999976,np.nan, inplace=True)\n",
    "pre_fasttext.replace(9999,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_fasttext.columns[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.replace(np.inf, np.nan, inplace=True)\n",
    "data.replace(-99998,np.nan, inplace=True)\n",
    "data.replace(-99999976,np.nan, inplace=True)\n",
    "data.replace(-9999979,np.nan, inplace=True)\n",
    "data.replace(-9999976,np.nan, inplace=True)\n",
    "data.replace(-999973,np.nan, inplace=True)\n",
    "data.replace(-999976,np.nan, inplace=True)\n",
    "data.replace(9999,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.replace('01. 坏',0)\n",
    "# data = data.replace('05. 好',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "continuousDomain, categoricalDomain = continuous_categorical(pre_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pre_fasttext['target_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB1\n",
      "TB5\n",
      "TB9\n",
      "TB3\n",
      "TB7\n",
      "TB11\n",
      "TB2\n",
      "TB6\n",
      "TB10\n",
      "TB4\n",
      "TB8\n",
      "TB12\n",
      "TB321\n",
      "TB322\n",
      "TB323\n",
      "TB324\n",
      "TB325\n",
      "TB326\n",
      "TB327\n",
      "TB328\n",
      "TB329\n",
      "TB330\n",
      "TB331\n",
      "TB332\n",
      "TB333\n",
      "TB334\n",
      "TB335\n",
      "TB336\n",
      "TB337\n",
      "TB338\n",
      "TB339\n",
      "TB340\n",
      "TB341\n",
      "TB342\n",
      "TB343\n",
      "TB344\n",
      "TB345\n",
      "TB346\n",
      "TB347\n",
      "TB348\n",
      "TB349\n",
      "TB434\n",
      "TB435\n",
      "TB436\n",
      "TB437\n",
      "TB366\n",
      "TB367\n",
      "TB368\n",
      "TB369\n",
      "TB370\n",
      "TB371\n",
      "TB372\n",
      "TB373\n",
      "TB374\n",
      "TB375\n",
      "TB376\n",
      "TB377\n",
      "TB378\n",
      "TB379\n",
      "TB380\n",
      "TB381\n",
      "TB382\n",
      "TB383\n",
      "TB384\n",
      "TB385\n",
      "TB386\n",
      "TB387\n",
      "TB388\n",
      "TB389\n",
      "TB390\n",
      "TB391\n",
      "TB392\n",
      "TB393\n",
      "TB394\n",
      "TB395\n",
      "TB396\n",
      "TB397\n",
      "TB13\n",
      "TB16\n",
      "TB19\n",
      "TB14\n",
      "TB17\n",
      "TB20\n",
      "TB15\n",
      "TB18\n",
      "TB21\n",
      "TB22\n",
      "TB26\n",
      "TB30\n",
      "TB24\n",
      "TB28\n",
      "TB32\n",
      "TB23\n",
      "TB27\n",
      "TB31\n",
      "TB25\n",
      "TB29\n",
      "TB33\n",
      "TB34\n",
      "TB38\n",
      "TB42\n",
      "TB46\n",
      "TB36\n",
      "TB40\n",
      "TB44\n",
      "TB48\n",
      "TB35\n",
      "TB39\n",
      "TB43\n",
      "TB47\n",
      "TB37\n",
      "TB41\n",
      "TB45\n",
      "TB49\n",
      "TB50\n",
      "TB54\n",
      "TB58\n",
      "TB62\n",
      "TB52\n",
      "TB56\n",
      "TB60\n",
      "TB64\n",
      "TB51\n",
      "TB55\n",
      "TB59\n",
      "TB63\n",
      "TB53\n",
      "TB57\n",
      "TB61\n",
      "TB65\n",
      "TB66\n",
      "TB74\n",
      "TB82\n",
      "TB68\n",
      "TB76\n",
      "TB84\n",
      "TB67\n",
      "TB75\n",
      "TB83\n",
      "TB69\n",
      "TB77\n",
      "TB85\n",
      "TB445\n",
      "TB446\n",
      "TB447\n",
      "TB448\n",
      "TB449\n",
      "TB450\n",
      "TB451\n",
      "TB452\n",
      "TB453\n",
      "TB454\n",
      "TB455\n",
      "TB456\n",
      "TB457\n",
      "TB458\n",
      "TB459\n",
      "TB460\n",
      "TB70\n",
      "TB78\n",
      "TB86\n",
      "TB71\n",
      "TB79\n",
      "TB87\n",
      "TB72\n",
      "TB80\n",
      "TB88\n",
      "TB73\n",
      "TB81\n",
      "TB89\n",
      "TB90\n",
      "TB91\n",
      "TB92\n",
      "TB93\n",
      "TB94\n",
      "TB97\n",
      "TB95\n",
      "TB98\n",
      "TB96\n",
      "TB99\n",
      "TB100\n",
      "TB103\n",
      "TB101\n",
      "TB104\n",
      "TB102\n",
      "TB105\n",
      "TB106\n",
      "TB112\n",
      "TB118\n",
      "TB110\n",
      "TB116\n",
      "TB122\n",
      "TB111\n",
      "TB117\n",
      "TB123\n",
      "TB124\n",
      "TB130\n",
      "TB136\n",
      "TB128\n",
      "TB134\n",
      "TB140\n",
      "TB129\n",
      "TB135\n",
      "TB141\n",
      "TB148\n",
      "TB157\n",
      "TB166\n",
      "TB175\n",
      "TB153\n",
      "TB162\n",
      "TB171\n",
      "TB180\n",
      "TB156\n",
      "TB165\n",
      "TB174\n",
      "TB183\n",
      "TB192\n",
      "TB200\n",
      "TB207\n",
      "TB195\n",
      "TB203\n",
      "TB209\n",
      "TB213\n",
      "TB218\n",
      "TB222\n",
      "TB215\n",
      "TB219\n",
      "TB223\n",
      "TB228\n",
      "TB233\n",
      "TB238\n",
      "TB243\n",
      "TB249\n",
      "TB255\n",
      "TB257\n",
      "TB262\n",
      "TB231\n",
      "TB236\n",
      "TB241\n",
      "TB247\n",
      "TB253\n",
      "TB260\n",
      "TB266\n",
      "TB232\n",
      "TB237\n",
      "TB242\n",
      "TB248\n",
      "TB254\n",
      "TB256\n",
      "TB261\n",
      "TB267\n",
      "TB268\n",
      "TB272\n",
      "TB276\n",
      "TB280\n",
      "TB270\n",
      "TB274\n",
      "TB278\n",
      "TB282\n",
      "TB269\n",
      "TB273\n",
      "TB277\n",
      "TB281\n",
      "TB271\n",
      "TB275\n",
      "TB279\n",
      "TB283\n",
      "TB284\n",
      "TB287\n",
      "TB290\n",
      "TB293\n",
      "TB285\n",
      "TB288\n",
      "TB291\n",
      "TB294\n",
      "TB286\n",
      "TB289\n",
      "TB292\n",
      "TB295\n",
      "TB543\n",
      "TB544\n",
      "TB545\n",
      "TB546\n",
      "TB548\n",
      "TB549\n",
      "TB550\n",
      "TB551\n",
      "TB547\n",
      "TB438\n",
      "TB439\n",
      "TB440\n",
      "TB552\n",
      "TB553\n",
      "TB554\n",
      "TB555\n",
      "TB443\n",
      "TB444\n",
      "TB441\n",
      "TB442\n",
      "TB556\n",
      "TB557\n",
      "TB398\n",
      "TB399\n",
      "TB400\n",
      "TB401\n",
      "TB402\n",
      "TB350\n",
      "TB354\n",
      "TB358\n",
      "TB362\n",
      "TB406\n",
      "TB407\n",
      "TB408\n",
      "TB409\n",
      "TB410\n",
      "TB351\n",
      "TB355\n",
      "TB359\n",
      "TB363\n",
      "TB414\n",
      "TB415\n",
      "TB416\n",
      "TB417\n",
      "TB418\n",
      "TB352\n",
      "TB356\n",
      "TB360\n",
      "TB364\n",
      "TB422\n",
      "TB423\n",
      "TB424\n",
      "TB425\n",
      "TB426\n",
      "TB353\n",
      "TB357\n",
      "TB361\n",
      "TB365\n",
      "TB558\n",
      "TB562\n",
      "TB563\n",
      "TB559\n",
      "TB560\n",
      "TB561\n",
      "TB564\n",
      "TB566\n",
      "TB567\n",
      "TB565\n",
      "TB568\n",
      "TB569\n",
      "TB570\n",
      "TB572\n",
      "TB573\n",
      "TB571\n",
      "TB574\n",
      "TB575\n",
      "TB576\n",
      "TB578\n",
      "TB579\n",
      "TB577\n",
      "TB580\n",
      "TB581\n",
      "TB142\n",
      "TB145\n",
      "TB143\n",
      "TB146\n",
      "TB144\n",
      "TB147\n",
      "TB107\n",
      "TB113\n",
      "TB119\n",
      "TB108\n",
      "TB114\n",
      "TB120\n",
      "TB125\n",
      "TB131\n",
      "TB137\n",
      "TB126\n",
      "TB132\n",
      "TB138\n",
      "TB229\n",
      "TB234\n",
      "TB239\n",
      "TB258\n",
      "TB230\n",
      "TB235\n",
      "TB240\n",
      "TB259\n",
      "TB244\n",
      "TB250\n",
      "TB263\n",
      "TB245\n",
      "TB251\n",
      "TB264\n",
      "TB226\n",
      "TB211\n",
      "TB216\n",
      "TB220\n",
      "TB224\n",
      "TB189\n",
      "TB197\n",
      "TB204\n",
      "TB227\n",
      "TB212\n",
      "TB217\n",
      "TB221\n",
      "TB225\n",
      "TB190\n",
      "TB198\n",
      "TB205\n",
      "TB150\n",
      "TB159\n",
      "TB168\n",
      "TB177\n",
      "TB151\n",
      "TB160\n",
      "TB169\n",
      "TB178\n",
      "TB185\n",
      "TB191\n",
      "TB199\n",
      "TB206\n",
      "TB186\n",
      "TB193\n",
      "TB201\n",
      "TB208\n",
      "TB184\n",
      "TB188\n",
      "TB196\n",
      "TB210\n",
      "TB187\n",
      "TB194\n",
      "TB202\n",
      "TB214\n",
      "TB152\n",
      "TB161\n",
      "TB170\n",
      "TB179\n",
      "TB154\n",
      "TB163\n",
      "TB172\n",
      "TB181\n",
      "TB149\n",
      "TB158\n",
      "TB167\n",
      "TB176\n",
      "TB155\n",
      "TB164\n",
      "TB173\n",
      "TB182\n",
      "TB109\n",
      "TB115\n",
      "TB121\n",
      "TB127\n",
      "TB133\n",
      "TB139\n",
      "TB246\n",
      "TB252\n",
      "TB265\n",
      "TB297\n",
      "TB296\n",
      "TO414_x\n",
      "TO415_x\n",
      "TO416_x\n",
      "TO417_x\n",
      "TO418_x\n",
      "TO9\n",
      "TO10\n",
      "TO52\n",
      "TO51\n",
      "TO17\n",
      "TO54\n",
      "TO27\n",
      "TO28\n",
      "TO29\n",
      "TO34\n",
      "TO36\n",
      "TO30\n",
      "TO35\n",
      "TO32\n",
      "TO31\n",
      "TO33\n",
      "TO49\n",
      "TO50\n",
      "TO60\n",
      "TO76\n",
      "TO98\n",
      "TO92\n",
      "TO157\n",
      "TO158\n",
      "TO159\n",
      "TO164\n",
      "TO166\n",
      "TO160\n",
      "TO165\n",
      "TO162\n",
      "TO161\n",
      "TO163\n",
      "TO179\n",
      "TO180\n",
      "TO67\n",
      "TO72\n",
      "TO75\n",
      "TO64\n",
      "TO83\n",
      "TO88\n",
      "TO91\n",
      "TO80\n",
      "TO105\n",
      "TO110\n",
      "TO113\n",
      "TO102\n",
      "TO63\n",
      "TO79\n",
      "TO101\n",
      "TO66\n",
      "TO82\n",
      "TO104\n",
      "TO68\n",
      "TO84\n",
      "TO106\n",
      "TO69\n",
      "TO85\n",
      "TO107\n",
      "TO374\n",
      "TO375\n",
      "TO376\n",
      "TO377\n",
      "TO378\n",
      "TO24\n",
      "TO25\n",
      "TO58\n",
      "TO57\n",
      "TO26\n",
      "TO59\n",
      "TO37\n",
      "TO38\n",
      "TO39\n",
      "TO44\n",
      "TO46\n",
      "TO40\n",
      "TO45\n",
      "TO42\n",
      "TO41\n",
      "TO43\n",
      "TO47\n",
      "TO48\n",
      "TO114\n",
      "TO128\n",
      "TO143\n",
      "TO142\n",
      "TO167\n",
      "TO168\n",
      "TO169\n",
      "TO174\n",
      "TO176\n",
      "TO170\n",
      "TO175\n",
      "TO172\n",
      "TO171\n",
      "TO173\n",
      "TO177\n",
      "TO178\n",
      "TO120\n",
      "TO134\n",
      "TO149\n",
      "TO124\n",
      "TO138\n",
      "TO153\n",
      "TO127\n",
      "TO141\n",
      "TO156\n",
      "TO117\n",
      "TO131\n",
      "TO146\n",
      "TO116\n",
      "TO130\n",
      "TO145\n",
      "TO119\n",
      "TO133\n",
      "TO148\n",
      "TO121\n",
      "TO135\n",
      "TO150\n",
      "TO122\n",
      "TO136\n",
      "TO151\n",
      "TO441\n",
      "TO442\n",
      "TO381\n",
      "TO443\n",
      "TO444\n",
      "TO183\n",
      "TO19\n",
      "TO23\n",
      "TO11\n",
      "TO18\n",
      "TO56\n",
      "TO53\n",
      "TO55\n",
      "TO21\n",
      "TO20\n",
      "TO22\n",
      "TO93\n",
      "TO96\n",
      "TO95\n",
      "TO97\n",
      "TO12\n",
      "TO15\n",
      "TO14\n",
      "TO16\n",
      "TO367\n",
      "TO365\n",
      "TO366\n",
      "TO370\n",
      "TO368\n",
      "TO369\n",
      "TO373\n",
      "TO371\n",
      "TO372\n",
      "TO384\n",
      "TO385\n",
      "TO386\n",
      "TO70\n",
      "TO62\n",
      "TO65\n",
      "TO86\n",
      "TO78\n",
      "TO81\n",
      "TO108\n",
      "TO100\n",
      "TO103\n",
      "TO73\n",
      "TO74\n",
      "TO89\n",
      "TO90\n",
      "TO111\n",
      "TO112\n",
      "TO61\n",
      "TO71\n",
      "TO99\n",
      "TO109\n",
      "TO77\n",
      "TO87\n",
      "TO94\n",
      "TO13\n",
      "TO123\n",
      "TO115\n",
      "TO118\n",
      "TO137\n",
      "TO129\n",
      "TO132\n",
      "TO152\n",
      "TO144\n",
      "TO147\n",
      "TO387\n",
      "TO388\n",
      "TO389\n",
      "TO125\n",
      "TO126\n",
      "TO139\n",
      "TO140\n",
      "TO154\n",
      "TO155\n",
      "TO185\n",
      "TO181\n",
      "TO184\n",
      "TO186\n",
      "TO182\n",
      "TO390\n",
      "TO391\n",
      "TO392\n",
      "TO393\n",
      "TO394\n",
      "TO395\n",
      "TO396\n",
      "TO397\n",
      "TO398\n",
      "TO399\n",
      "TO400\n",
      "TO401\n",
      "TO402\n",
      "TO403\n",
      "TO404\n",
      "TO405\n",
      "TO406\n",
      "TO407\n",
      "TO408\n",
      "TO409\n",
      "TO410\n",
      "TO411\n",
      "TO412\n",
      "TO413\n",
      "TO414_y\n",
      "TO415_y\n",
      "TO416_y\n",
      "TO417_y\n",
      "TO418_y\n",
      "TO419\n",
      "TO420\n",
      "TO421\n",
      "TO422\n",
      "TO423\n",
      "TO424\n",
      "TO425\n",
      "TO426\n",
      "TO427\n",
      "TO428\n",
      "TO429\n",
      "TO430\n",
      "TO431\n",
      "TO432\n",
      "TO433\n",
      "TO434\n",
      "TO222\n",
      "TO234\n",
      "TO1\n",
      "TO2\n",
      "TO273\n",
      "TO268\n",
      "TO3\n",
      "TO332\n",
      "TO333\n",
      "TO334\n",
      "TO339\n",
      "TO341\n",
      "TO335\n",
      "TO340\n",
      "TO337\n",
      "TO336\n",
      "TO338\n",
      "TO354\n",
      "TO355\n",
      "TO238\n",
      "TO253\n",
      "TO274\n",
      "TO248\n",
      "TO263\n",
      "TO284\n",
      "TO244\n",
      "TO259\n",
      "TO280\n",
      "TO249\n",
      "TO264\n",
      "TO285\n",
      "TO252\n",
      "TO267\n",
      "TO288\n",
      "TO241\n",
      "TO256\n",
      "TO277\n",
      "TO240\n",
      "TO255\n",
      "TO276\n",
      "TO243\n",
      "TO258\n",
      "TO279\n",
      "TO245\n",
      "TO260\n",
      "TO281\n",
      "TO246\n",
      "TO261\n",
      "TO282\n",
      "TO435\n",
      "TO436\n",
      "TO437\n",
      "TO289\n",
      "TO303\n",
      "TO4\n",
      "TO5\n",
      "TO318\n",
      "TO317\n",
      "TO6\n",
      "TO342\n",
      "TO343\n",
      "TO344\n",
      "TO349\n",
      "TO351\n",
      "TO345\n",
      "TO350\n",
      "TO347\n",
      "TO346\n",
      "TO348\n",
      "TO352\n",
      "TO353\n",
      "TO295\n",
      "TO309\n",
      "TO324\n",
      "TO299\n",
      "TO313\n",
      "TO328\n",
      "TO302\n",
      "TO316\n",
      "TO331\n",
      "TO292\n",
      "TO306\n",
      "TO321\n",
      "TO291\n",
      "TO305\n",
      "TO320\n",
      "TO294\n",
      "TO308\n",
      "TO323\n",
      "TO296\n",
      "TO310\n",
      "TO325\n",
      "TO297\n",
      "TO311\n",
      "TO326\n",
      "TO438\n",
      "TO439\n",
      "TO440\n",
      "TO231\n",
      "TO232\n",
      "TO230\n",
      "TO357\n",
      "TO358\n",
      "TO356\n",
      "TO233\n",
      "TO250\n",
      "TO251\n",
      "TO265\n",
      "TO266\n",
      "TO286\n",
      "TO287\n",
      "TO247\n",
      "TO239\n",
      "TO242\n",
      "TO262\n",
      "TO254\n",
      "TO257\n",
      "TO283\n",
      "TO275\n",
      "TO278\n",
      "TO300\n",
      "TO301\n",
      "TO314\n",
      "TO315\n",
      "TO329\n",
      "TO330\n",
      "TO298\n",
      "TO290\n",
      "TO293\n",
      "TO312\n",
      "TO304\n",
      "TO307\n",
      "TO327\n",
      "TO319\n",
      "TO322\n",
      "TO237\n",
      "TO235\n",
      "TO236\n",
      "TO229\n",
      "TO223\n",
      "TO228\n",
      "TO224\n",
      "TO226\n",
      "TO225\n",
      "TO227\n",
      "TO269\n",
      "TO271\n",
      "TO270\n",
      "TO272\n",
      "TO197\n",
      "TO210\n",
      "TO200\n",
      "TO213\n",
      "TO202\n",
      "TO215\n",
      "TO203\n",
      "TO216\n",
      "TO206\n",
      "TO207\n",
      "TO219\n",
      "TO220\n",
      "TO204\n",
      "TO196\n",
      "TO199\n",
      "TO217\n",
      "TO209\n",
      "TO212\n",
      "TO201\n",
      "TO214\n",
      "TO205\n",
      "TO218\n",
      "TO208\n",
      "TO221\n",
      "TO198\n",
      "TO211\n",
      "perf\n",
      "prob\n"
     ]
    }
   ],
   "source": [
    "# data[['perf']]\n",
    "for i in pre_fasttext.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for j in data.columns:\n",
    "#     print(j)\n",
    "# a = pd.merge(data,pre_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfm = DataFrameMapper([(c, [CategoricalDomain(invalid_value_treatment = 'as_missing',\n",
    "                                              missing_value_treatment = 'as_value',\n",
    "                                              missing_value_replacement = 'N/A'), LabelBinarizer()])\n",
    "                       for c in categoricalDomain] \n",
    "                      + \n",
    "                     [(c, [ContinuousDomain(invalid_value_treatment = 'as_missing',\n",
    "                                                     missing_value_treatment = 'as_value',\n",
    "                                                     missing_value_replacement = -1)])\n",
    "                      for c in continuousDomain]\n",
    "                      ,df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 50s, sys: 256 ms, total: 5min 50s\n",
      "Wall time: 5min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(default=False, df_out=True,\n",
       "        features=[('TO9', [ContinuousDomain()]), ('TO10', [ContinuousDomain()]), ('TO52', [ContinuousDomain()]), ('TO51', [ContinuousDomain()]), ('TO17', [ContinuousDomain()]), ('TO54', [ContinuousDomain()]), ('TO27', [ContinuousDomain()]), ('TO28', [ContinuousDomain()]), ('TO29', [ContinuousDomain()]), ('T...'TO417_y', [ContinuousDomain()]), ('TO418_y', [ContinuousDomain()]), ('perf', [ContinuousDomain()])],\n",
       "        input_df=False, sparse=False)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dfm.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn2pmml/decoration/__init__.py:100: RuntimeWarning: Mean of empty slice\n",
      "  \"mean\" : numpy.asarray(numpy.nanmean(X, axis = 0)),\n",
      "/opt/anaconda3/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1434: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(default=False, df_out=True,\n",
       "        features=[('TB1', [ContinuousDomain()]), ('TB5', [ContinuousDomain()]), ('TB9', [ContinuousDomain()]), ('TB3', [ContinuousDomain()]), ('TB7', [ContinuousDomain()]), ('TB11', [ContinuousDomain()]), ('TB2', [ContinuousDomain()]), ('TB6', [ContinuousDomain()]), ('TB10', [ContinuousDomain()]), ('TB4', [...), ('TO198', [ContinuousDomain()]), ('TO211', [ContinuousDomain()]), ('perf', [ContinuousDomain()])],\n",
       "        input_df=False, sparse=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.fit(pre_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[data.perf.isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_fasttext=pre_fasttext[pre_fasttext.perf.isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=2018)#调用sklearn中的方法，注意指定随机种子，保证结果可以复线\n",
    "\n",
    "# print(train.shape)\n",
    "# print(test.shape)\n",
    "# print(X_train.shape)\n",
    "# print(train.target.value_counts())#查看训练集好坏分布\n",
    "# print(test.target.value_counts())#查看测试集好坏分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = dfm.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['perf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(\"perf\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61822, 889)\n",
      "(6870, 889)\n",
      "(61822, 888)\n",
      "1    32111\n",
      "0    29711\n",
      "Name: perf, dtype: int64\n",
      "1    3600\n",
      "0    3270\n",
      "Name: perf, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(X_train.shape)\n",
    "print(train.perf.value_counts())#查看训练集好坏分布\n",
    "print(test.perf.value_counts())#查看测试集好坏分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TO9', 'TO10', 'TO52', 'TO51', 'TO17', 'TO54', 'TO27', 'TO28', 'TO29',\n",
       "       'TO34',\n",
       "       ...\n",
       "       'TB246', 'TB252', 'TB265', 'TB297', 'TB296', 'TO414_y', 'TO415_y',\n",
       "       'TO416_y', 'TO417_y', 'TO418_y'],\n",
       "      dtype='object', length=888)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varlist=X_train.columns\n",
    "varlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.82622520164901361,\n",
    "        drop_rate=0.5, is_unbalance=True,\n",
    "        learning_rate=0.025, max_bin=4, max_depth=3,\n",
    "        max_drop=50, min_child_samples=120, min_child_weight=3,\n",
    "        min_split_gain=0.028, n_estimators=705, nthread=-1,\n",
    "        num_leaves=128, objective='binary', reg_alpha=30, reg_lambda=150,\n",
    "        scale_pos_weight=1, seed=27, sigmoid=1.0, silent=True,\n",
    "        skip_drop=0.5, subsample=0.7, subsample_for_bin=30000,\n",
    "        subsample_freq=3, uniform_drop=False, xgboost_dart_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.82622520164901361,\n",
    "        drop_rate=0.5, is_unbalance=True,\n",
    "        learning_rate=0.03, max_bin=10, max_depth=5,\n",
    "        max_drop=50, min_child_samples=1200, min_child_weight=4,\n",
    "        min_split_gain=0.01500339778285961, n_estimators=490, nthread=-1,\n",
    "        num_leaves=128, objective='binary', reg_alpha=20, reg_lambda=100,\n",
    "        scale_pos_weight=1, seed=27, sigmoid=1.0, silent=True,\n",
    "        skip_drop=0.5, subsample=0.7, subsample_for_bin=30000,\n",
    "        subsample_freq=3, uniform_drop=False, xgboost_dart_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelWithCv(model, x_array, y_array, cv=5):\n",
    "    model.fit(x_array, y_array)\n",
    "    \n",
    "    dtrain_predictions = model.predict(x_array)\n",
    "    dtrain_predprob = model.predict_proba(x_array)[:,1]\n",
    "    \n",
    "    print(\"--AUC Score (Train): %f\" % roc_auc_score(y_array, dtrain_predprob))\n",
    "    print (\"class metrics:\")\n",
    "    print (metrics.classification_report(y_array, dtrain_predictions))\n",
    "    \n",
    "    cv_score = cross_val_score(model,x_array, y_array, cv=cv, scoring = 'roc_auc')\n",
    "    print(\"--CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" %(np.mean(cv_score), np.std(cv_score), np.min(cv_score), np.max(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--AUC Score (Train): 0.757755\n",
      "class metrics:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.70      0.69     29711\n",
      "          1       0.71      0.68      0.69     32111\n",
      "\n",
      "avg / total       0.69      0.69      0.69     61822\n",
      "\n",
      "--CV Score : Mean - 0.7223358 | Std - 0.0003219352 | Min - 0.7220138 | Max - 0.7226577\n",
      "CPU times: user 5h 13min 19s, sys: 1min 12s, total: 5h 14min 32s\n",
      "Wall time: 12min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelWithCv(model, X_train, y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext_main_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train['prob']\n",
    "df_train=dfm.transform(data)\n",
    "all_prob = pd.DataFrame(model.predict_proba(df_train[varlist])[:,1], columns = ['predprob'])\n",
    "all_prob['ytrue'] = data['perf'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv(\"data/fasttext_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_prob['fastprob']=data_0['prob'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_fasttext['perf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pre=dfm.transform(pre_fasttext)\n",
    "pre_prob = pd.DataFrame(model.predict_proba(df_pre[varlist])[:,1], columns = ['predprob'])\n",
    "pre_prob['ytrue'] = pre_fasttext['perf'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_prob\n",
    "pre_f = pd.read_csv('data/pre_all_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_prob['fastprob']=pre_f['prob'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_f)==len(pre_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_prob['prob']=0.0\n",
    "all_prob['prob']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prob, test_prob = train_test_split(all_prob, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predprob</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>fastprob</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.757769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.581823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.837402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.649922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.795014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.662916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.613261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.335335</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502666</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.470683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.408449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513140</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.427734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272883</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.275215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239058</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.302244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.538354</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.277232</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.736603</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.594850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.332248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443848</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.510811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.479334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.450876</td>\n",
       "      <td>0</td>\n",
       "      <td>0.628671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.655466</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.755593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.201728</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.509811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.297861</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489464</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.299135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.408688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.278215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.545531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21935</th>\n",
       "      <td>0.689890</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533796</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21936</th>\n",
       "      <td>0.524142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21937</th>\n",
       "      <td>0.487545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21938</th>\n",
       "      <td>0.282982</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364291</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21939</th>\n",
       "      <td>0.661626</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21940</th>\n",
       "      <td>0.682915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501237</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21941</th>\n",
       "      <td>0.750335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21942</th>\n",
       "      <td>0.841329</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>0.503584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0.282114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0.389129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0.157495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.252546</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>0.451102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21948</th>\n",
       "      <td>0.327350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21949</th>\n",
       "      <td>0.383511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756734</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21950</th>\n",
       "      <td>0.396701</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21951</th>\n",
       "      <td>0.761350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21952</th>\n",
       "      <td>0.539527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21953</th>\n",
       "      <td>0.349178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544731</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21954</th>\n",
       "      <td>0.488003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21955</th>\n",
       "      <td>0.622181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402650</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21956</th>\n",
       "      <td>0.403867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611657</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21957</th>\n",
       "      <td>0.585284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21958</th>\n",
       "      <td>0.585444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21959</th>\n",
       "      <td>0.536789</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21960</th>\n",
       "      <td>0.449564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421334</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21961</th>\n",
       "      <td>0.407472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21962</th>\n",
       "      <td>0.201987</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21963</th>\n",
       "      <td>0.638304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21964</th>\n",
       "      <td>0.311670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517867</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21965 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predprob  ytrue  fastprob  prob\n",
       "0      0.610502      1  0.679297   0.0\n",
       "1      0.757769      1  0.577517   0.0\n",
       "2      0.581823      0  0.386687   0.0\n",
       "3      0.837402      1  0.649922   0.0\n",
       "4      0.795014      1  0.662916   0.0\n",
       "5      0.613261      0  0.507287   0.0\n",
       "6      0.335335      0  0.502666   0.0\n",
       "7      0.470683      0  0.481760   0.0\n",
       "8      0.408449      0  0.513140   0.0\n",
       "9      0.500290      0  0.643847   0.0\n",
       "10     0.427734      0  0.272883   0.0\n",
       "11     0.275215      0  0.239058   0.0\n",
       "12     0.302244      0  0.456251   0.0\n",
       "13     0.538354      1  0.623003   0.0\n",
       "14     0.277232      0  0.537997   0.0\n",
       "15     0.736603      1  0.541309   0.0\n",
       "16     0.594850      1  0.753515   0.0\n",
       "17     0.332248      0  0.443848   0.0\n",
       "18     0.510811      0  0.407345   0.0\n",
       "19     0.479334      1  0.530769   0.0\n",
       "20     0.450876      0  0.628671   0.0\n",
       "21     0.655466      1  0.771352   0.0\n",
       "22     0.755593      1  0.741325   0.0\n",
       "23     0.201728      0  0.332201   0.0\n",
       "24     0.509811      0  0.555364   0.0\n",
       "25     0.297861      0  0.489464   0.0\n",
       "26     0.299135      0  0.560409   0.0\n",
       "27     0.408688      0  0.695920   0.0\n",
       "28     0.278215      0  0.308508   0.0\n",
       "29     0.545531      1  0.429854   0.0\n",
       "...         ...    ...       ...   ...\n",
       "21935  0.689890      1  0.533796   0.0\n",
       "21936  0.524142      1  0.624083   0.0\n",
       "21937  0.487545      0  0.623847   0.0\n",
       "21938  0.282982      0  0.364291   0.0\n",
       "21939  0.661626      0  0.429980   0.0\n",
       "21940  0.682915      1  0.501237   0.0\n",
       "21941  0.750335      1  0.669788   0.0\n",
       "21942  0.841329      1  0.570330   0.0\n",
       "21943  0.503584      0  0.710426   0.0\n",
       "21944  0.282114      1  0.123171   0.0\n",
       "21945  0.389129      1  0.710705   0.0\n",
       "21946  0.157495      0  0.252546   0.0\n",
       "21947  0.451102      0  0.587176   0.0\n",
       "21948  0.327350      0  0.349209   0.0\n",
       "21949  0.383511      1  0.756734   0.0\n",
       "21950  0.396701      0  0.840301   0.0\n",
       "21951  0.761350      0  0.579425   0.0\n",
       "21952  0.539527      1  0.514118   0.0\n",
       "21953  0.349178      0  0.544731   0.0\n",
       "21954  0.488003      0  0.693290   0.0\n",
       "21955  0.622181      1  0.402650   0.0\n",
       "21956  0.403867      0  0.611657   0.0\n",
       "21957  0.585284      1  0.506216   0.0\n",
       "21958  0.585444      1  0.644496   0.0\n",
       "21959  0.536789      1  0.693570   0.0\n",
       "21960  0.449564      0  0.421334   0.0\n",
       "21961  0.407472      0  0.619939   0.0\n",
       "21962  0.201987      0  0.176261   0.0\n",
       "21963  0.638304      0  0.685252   0.0\n",
       "21964  0.311670      0  0.517867   0.0\n",
       "\n",
       "[21965 rows x 4 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6870"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = []\n",
    "for i in range(len(train_prob)):\n",
    "    train_label.append(train_prob.iat[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = []\n",
    "for i in range(len(test_prob)):\n",
    "    test_label.append(test_prob.iat[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_label = []\n",
    "for i in range(len(pre_prob)):\n",
    "    pre_label.append(pre_prob.iat[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(test_label)\n",
    "import numpy as np\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)\n",
    "pre_label = np.array(pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "def cal_ks_scipy(y_pred,y_true):\n",
    "    return ks_2samp(y_pred[y_true==1],y_pred[y_true!=1]).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is 0.0\n",
      "train ks is  0.2505774202563977\n",
      "test ks is  0.24735983690112134\n",
      "pre ks is  0.21895410064827364\n",
      "a is 0.05\n",
      "train ks is  0.26624348727345054\n",
      "test ks is  0.25984709480122326\n",
      "pre ks is  0.23087950396668333\n",
      "a is 0.1\n",
      "train ks is  0.2813224466479464\n",
      "test ks is  0.2712079510703364\n",
      "pre ks is  0.24346192273532796\n",
      "a is 0.15\n",
      "train ks is  0.295010994503295\n",
      "test ks is  0.2794367991845056\n",
      "pre ks is  0.25447420673380894\n",
      "a is 0.2\n",
      "train ks is  0.30901643458130956\n",
      "test ks is  0.2899515800203874\n",
      "pre ks is  0.26590868488432673\n",
      "a is 0.25\n",
      "train ks is  0.32222267434158725\n",
      "test ks is  0.29450560652395513\n",
      "pre ks is  0.2752900540068259\n",
      "a is 0.3\n",
      "train ks is  0.3343769481848739\n",
      "test ks is  0.30529306829765546\n",
      "pre ks is  0.28268776641974025\n",
      "a is 0.35\n",
      "train ks is  0.3445218900657505\n",
      "test ks is  0.3129612640163099\n",
      "pre ks is  0.2906563690967975\n",
      "a is 0.4\n",
      "train ks is  0.35259530093289526\n",
      "test ks is  0.31472731906218143\n",
      "pre ks is  0.2990452092890109\n",
      "a is 0.45\n",
      "train ks is  0.3613371935911517\n",
      "test ks is  0.32299949031600406\n",
      "pre ks is  0.3035949455227522\n",
      "a is 0.5\n",
      "train ks is  0.36762412561428215\n",
      "test ks is  0.3287054026503568\n",
      "pre ks is  0.30803835180735706\n",
      "a is 0.55\n",
      "train ks is  0.37225780033369965\n",
      "test ks is  0.3336416921508664\n",
      "pre ks is  0.31300418842996836\n",
      "a is 0.6\n",
      "train ks is  0.3767050770501557\n",
      "test ks is  0.33683995922528026\n",
      "pre ks is  0.31632936844636506\n",
      "a is 0.65\n",
      "train ks is  0.37992406688748104\n",
      "test ks is  0.34001783893985726\n",
      "pre ks is  0.317800502364861\n",
      "a is 0.7\n",
      "train ks is  0.38190541813377493\n",
      "test ks is  0.34033893985728847\n",
      "pre ks is  0.31724097054362765\n",
      "a is 0.75\n",
      "train ks is  0.38311849406882353\n",
      "test ks is  0.34394495412844034\n",
      "pre ks is  0.3164135369955761\n",
      "a is 0.8\n",
      "train ks is  0.3835164910621066\n",
      "test ks is  0.34464067278287464\n",
      "pre ks is  0.31669509372638877\n",
      "a is 0.85\n",
      "train ks is  0.3847851720539056\n",
      "test ks is  0.3439857288481142\n",
      "pre ks is  0.3148270029552845\n",
      "a is 0.9\n",
      "train ks is  0.38358964027418013\n",
      "test ks is  0.3413047910295617\n",
      "pre ks is  0.3118453868189863\n",
      "a is 0.95\n",
      "train ks is  0.38280540143768854\n",
      "test ks is  0.3395208970438328\n",
      "pre ks is  0.308719551621072\n",
      "a is 1.0\n",
      "train ks is  0.3814966481193178\n",
      "test ks is  0.33494393476044854\n",
      "pre ks is  0.30643346186005666\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,5):\n",
    "    train_prob_list = []\n",
    "    test_prob_list = []\n",
    "    pre_prob_list = []\n",
    "    a = i/100\n",
    "    for j in range(len(train_prob)):\n",
    "        train_prob_list.append(a*train_prob.iat[j,0]+(1-a)*train_prob.iat[j,2])\n",
    "    for j in range(len(test_prob)):\n",
    "        test_prob_list.append(a*test_prob.iat[j,0]+(1-a)*test_prob.iat[j,2])\n",
    "    for j in range(len(pre_prob)):\n",
    "        pre_prob_list.append(a*pre_prob.iat[j,0]+(1-a)*pre_prob.iat[j,2])\n",
    "    train_prob_list = np.array(train_prob_list)\n",
    "    test_prob_list = np.array(test_prob_list)\n",
    "    pre_prob_list = np.array(pre_prob_list)\n",
    "    print(\"a is\",a)\n",
    "    print(\"train ks is \",cal_ks_scipy(train_prob_list,train_label))\n",
    "    print(\"test ks is \",cal_ks_scipy(test_prob_list,test_label))\n",
    "    print(\"pre ks is \",cal_ks_scipy(pre_prob_list,pre_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC On Test is: 0.7092076114766503\n",
      "KS On Test is: 0.30643346186005666\n",
      "AUC On Train is: 0.7577553942274264\n",
      "KS On Train is: 0.3814966481193178\n"
     ]
    }
   ],
   "source": [
    "pro,true,test_pro,test_true = auc_ks(model, dfm, train, pre_fasttext, varlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# youhuachengdutuiduan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_mainfalse_fasttrue_yfalse = pre_prob[pre_prob.predprob>0.5][pre_prob.ytrue==0][pre_prob.fastprob<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_mainfalse_fasttrue_ytrue = pre_prob[pre_prob.predprob<0.5][pre_prob.ytrue==1][pre_prob.fastprob>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14409287502845436"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_mainfalse_fasttrue_ytrue)+len(pre_mainfalse_fasttrue_yfalse))/len(pre_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_maintrue_fastfalse_ytrue = pre_prob[pre_prob.predprob>0.5][pre_prob.ytrue==1][pre_prob.fastprob<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_maintrue_fastfalse_yfalse= pre_prob[pre_prob.predprob<0.5][pre_prob.ytrue==0][pre_prob.fastprob>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1915319826997496"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_maintrue_fastfalse_ytrue)+len(pre_maintrue_fastfalse_yfalse))/len(pre_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_maintrue_fasttrue_yfalse= pre_prob[pre_prob.predprob<0.5][pre_prob.ytrue==0][pre_prob.fastprob<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_maintrue_fasttrue_ytrue= pre_prob[pre_prob.predprob>0.5][pre_prob.ytrue==1][pre_prob.fastprob>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4599590257227407"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_maintrue_fasttrue_yfalse)+len(pre_maintrue_fasttrue_ytrue))/len(pre_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_mainfalse_fastfalse_yfalse= pre_prob[pre_prob.predprob>0.5][pre_prob.ytrue==0][pre_prob.fastprob>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pre_mainfalse_fastfalse_ytrue= pre_prob[pre_prob.predprob<0.5][pre_prob.ytrue==1][pre_prob.fastprob<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2044161165490553"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_mainfasle_fastfalse_yfalse)+len(pre_mainfalse_fastfalse_ytrue))/len(pre_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41345525800130634"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_mainfalse_fasttrue_ytrue)+len(pre_mainfalse_fasttrue_yfalse))/(len(pre_mainfalse_fasttrue_ytrue)+len(pre_mainfalse_fasttrue_yfalse)+\n",
    "                                                                       len(pre_mainfalse_fastfalse_ytrue)+len(pre_mainfalse_fastfalse_yfalse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1042"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_mainfalse_fasttrue_ytrue)+len(pre_mainfalse_fasttrue_yfalse))-(len(pre_maintrue_fastfalse_yfalse)+len(pre_maintrue_fastfalse_ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2939902166317261"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pre_maintrue_fastfalse_yfalse)+len(pre_maintrue_fastfalse_ytrue))/(\n",
    "    len(pre_maintrue_fastfalse_ytrue)+len(pre_maintrue_fastfalse_yfalse)+\n",
    "    len(pre_maintrue_fasttrue_ytrue)+len(pre_maintrue_fasttrue_yfalse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn  adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2,min_samples_split=20,min_samples_leaf=4),algorithm=\"SAMME\", \n",
    "                         n_estimators=200,learning_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_1 = AdaBoostClassifier(n_estimators=200,learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_2 = AdaBoostClassifier(n_estimators=700,learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score = cross_val_score(clf,data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_ada = clf.fit(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_ada_1 = clf_1.fit(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ada_2 = clf_2.fit(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p_ada =  model_ada_2.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_p_ada = model_ada_2.predict_proba(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_p_ada = model_ada_2.predict_proba(data_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_ada = model_ada.predict(data)\n",
    "# train_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prob_ada = []\n",
    "for i in range(len(train_p_ada)):\n",
    "    train_p_ada = list(train_p_ada)\n",
    "    train_prob_ada.append(train_p_ada[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prob_ada = []\n",
    "for i in range(len(test_p_ada)):\n",
    "    test_p_ada = list(test_p_ada)\n",
    "    test_prob_ada.append(test_p_ada[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_prob_ada = []\n",
    "for i in range(len(pre_p_ada)):\n",
    "    pre_p_ada = list(pre_p_ada)\n",
    "    pre_prob_ada.append(pre_p_ada[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prob_ada = np.array(train_prob_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prob_ada = np.array(test_prob_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_prob_ada = np.array(pre_prob_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49974856, 0.49991385, 0.50047877, ..., 0.50011079, 0.49973949,\n",
       "       0.49968061])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38671678481277294"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ks_scipy(train_prob_ada,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3450229357798165"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ks_scipy(test_prob_ada,test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3135390384376673"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ks_scipy(pre_prob_ada,pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'base_estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'n_estimators': 100,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ada.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
